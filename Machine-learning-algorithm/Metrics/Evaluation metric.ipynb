{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics for Machine learning model\n",
    "\n",
    "- Evaluation is always good in any field right! In the case of machine learning, it is best the practice. In this post, I will almost cover all the popular as well as common metrics used for machine learning.\n",
    "\n",
    "-  Different performance metrics are used to evaluate different Machine Learning Algorithms. For now, we will be focusing on the ones used for Classification problems.\n",
    "\n",
    "The Classification Metric Are:\n",
    "  \n",
    "       1. Confusion Matrix\n",
    "       2. Accuracy\n",
    "       3. Precision\n",
    "       4. Recall\n",
    "       5. Specificity\n",
    "       6. F1-Score\n",
    "       7. Roc And Auc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Confusion Matrix :\n",
    "\n",
    "- The Confusion matrix is one of the most intuitive and easiest metrics used for finding the correctness and accuracy of the model. It is only used for Classification problem where the output can be of two or more types of classes.\n",
    "\n",
    "There are 4 terms you should keep in mind:\n",
    "\n",
    "        1. True Positives (TP): It is the case where we predicted Yes and the real output was also yes.\n",
    "        2. True Negatives (TN): It is the case where we predicted No and the real output was also No.\n",
    "        3. False Positives (FP): It is the case where we predicted Yes but it was actually No.\n",
    "        4. False Negatives (FN): It is the case where we predicted No but it was actually Yes.\n",
    "        \n",
    "Lets Take an example to know better this 4 term :\n",
    "\n",
    "  Let’s give a label of to our target variable:\n",
    "  \n",
    "1: When a person is having Corona\n",
    "\n",
    "0: When a person is NOT having Corona.\n",
    "\n",
    "Now lets apply this corona example in to this 4 term:\n",
    "\n",
    "1. True Positives (TP) :- Ex: The case where a person is actually having Corona(1) and the model also predict person haing  Corona(1) Then it comes under True positive(TP).\n",
    "\n",
    "\n",
    "\n",
    "2. True Negatives (TN) :- Ex: The case where a person NOT having Corona(0) and the model also prdict person Not Having Corona(0) Then it comes under True Negatives(TN).\n",
    "\n",
    "\n",
    "\n",
    "3. False Positives (FP) :- Ex: A person NOT having Corona(0) But the model is predict Person haing Corona(1) Then It comes under False Positives (FP).\n",
    "\n",
    "\n",
    "\n",
    "4. False Negatives (FN)  :- Ex: A person having Corona (1) But the model predict Person not Haing Corona (0) Then it comes under False Negatives(FN). \n",
    "\n",
    "SO in the above example you see these 4 type of term associate with Confusion Matrix.\n",
    "\n",
    "<img src=\"1.jpeg\" width=500>\n",
    "\n",
    "\n",
    "\n",
    "-  we all want is that the model should give 0 False Positives and 0 False Negatives. \n",
    "- But that’s not the case in real life as any model will NOT be 100% accurate most of the times.\n",
    "- So we might want to minimise either False Positives or False negatives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Accuracy :\n",
    "\n",
    "- Accuracy in classification problems is the number of correct predictions made by the model over all kinds predictions made.\n",
    "\n",
    "<img src =\"2.jpeg\" width= 500>\n",
    "<img src = \"2.png\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* Accuracy is a good measure when the target variable classes in the data are nearly balanced.\n",
    "* Accuracy should NEVER be used as a measure when the target variable classes in the data are a majority of one class. (imbalanced dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Precision :\n",
    "\n",
    "<img src=\"3.jpeg\" width=500>\n",
    "<img src=\"3.png\">\n",
    "\n",
    "- Precision is a measure that tells us what proportion of patients that we diagnosed as having Corona, actually had Corona. The predicted positives (Total People predicted as Corona are TP and FP) and the people actually having a Corona are TP.\n",
    "<br><br>\n",
    "- precision gives us information about its performance with respect to false positives(how many did we caught).\n",
    "- Precision is about being precise. So even if we managed to capture only one Corona case, and we captured it correctly, then we are 100% precise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.  Recall or Sensitivity:\n",
    "\n",
    "<img src=\"4.jpeg\" width=500>\n",
    "<img src=\"4.png\">\n",
    "\n",
    "\n",
    "- Recall is a measure that tells us what proportion of patients that actually had Corona was diagnosed by the algorithm as having Corona. The actual positives (People having Corona are TP and FN) and the people diagnosed by the model having a Corona are TP. (Note: FN is included because the Person actually had a Corona even though the model predicted otherwise).\n",
    "\n",
    "<br><br>\n",
    "\n",
    "- It is clear that recall gives us information about a classifier’s performance with respect to false negatives (how many did we miss).\n",
    "- Recall is not so much about capturing cases correctly but more about capturing all cases that have “Corona” with the answer as “Corona”. So if we simply always say every case as “Corona”, we have 100% recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  5. Specificity :\n",
    "\n",
    "<img src=\"5.jpeg\" width=500>\n",
    "<img src=\"5.png\">\n",
    "\n",
    "- Specificity is the exact opposite of Recall.\n",
    "- Specificity is a measure that tells us what proportion of patients that did NOT have Corona, were predicted by the model as not Corona . The actual negatives (People actually NOT having Corona are FP and TN) and the people diagnosed by us not having Corona are TN. (Note: FP is included because the Person did NOT actually have Corona even though the model predicted otherwie)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All 4 Metric :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Accuracy 2. Precision  3. Recall or Sensitivity 4.Specificity \n",
    "\n",
    "<img src=\"all-in-one.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f1-score and Roc Auc i am explain in next notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
